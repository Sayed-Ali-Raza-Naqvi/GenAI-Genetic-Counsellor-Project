{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCBJQxpfjs0V",
        "outputId": "93215e13-d023-4140-c4e5-8b89b97d9b29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_ner_bionlp13cg_md-0.5.1.tar.gz\n",
            "  Downloading https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_ner_bionlp13cg_md-0.5.1.tar.gz (120.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.2/120.2 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting scispacy\n",
            "  Downloading scispacy-0.5.5-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from scispacy) (3.7.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from scispacy) (1.13.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scispacy) (2.32.3)\n",
            "Collecting conllu (from scispacy)\n",
            "  Downloading conllu-6.0.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from scispacy) (1.26.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from scispacy) (1.4.2)\n",
            "Requirement already satisfied: scikit-learn>=0.20.3 in /usr/local/lib/python3.10/dist-packages (from scispacy) (1.5.2)\n",
            "Collecting pysbd (from scispacy)\n",
            "  Downloading pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting nmslib>=1.7.3.6 (from scispacy)\n",
            "  Downloading nmslib-2.1.1.tar.gz (188 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "INFO: pip is looking at multiple versions of en-ner-bionlp13cg-md to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting scispacy\n",
            "  Downloading scispacy-0.5.4-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting scipy<1.11 (from scispacy)\n",
            "  Downloading scipy-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.9/58.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scispacy\n",
            "  Downloading scispacy-0.5.3-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting spacy<3.7.0,>=3.6.0 (from scispacy)\n",
            "  Downloading spacy-3.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting scispacy\n",
            "  Downloading scispacy-0.5.2-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting spacy<3.5.0,>=3.4.0 (from scispacy)\n",
            "  Downloading spacy-3.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (24 kB)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.0->scispacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.0->scispacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.0->scispacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.0->scispacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.0->scispacy) (3.0.9)\n",
            "Collecting thinc<8.2.0,>=8.1.0 (from spacy<3.5.0,>=3.4.0->scispacy)\n",
            "  Downloading thinc-8.1.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
            "Collecting wasabi<1.1.0,>=0.9.1 (from spacy<3.5.0,>=3.4.0->scispacy)\n",
            "  Downloading wasabi-0.10.1-py3-none-any.whl.metadata (28 kB)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.0->scispacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.0->scispacy) (2.0.10)\n",
            "Collecting typer<0.8.0,>=0.3.0 (from spacy<3.5.0,>=3.4.0->scispacy)\n",
            "  Downloading typer-0.7.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting pathy>=0.3.5 (from spacy<3.5.0,>=3.4.0->scispacy)\n",
            "  Downloading pathy-0.11.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting smart-open<7.0.0,>=5.2.1 (from spacy<3.5.0,>=3.4.0->scispacy)\n",
            "  Downloading smart_open-6.4.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.0->scispacy) (4.66.6)\n",
            "Collecting pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 (from spacy<3.5.0,>=3.4.0->scispacy)\n",
            "  Downloading pydantic-1.10.19-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (152 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.6/152.6 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.0->scispacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.0->scispacy) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.0->scispacy) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.0->scispacy) (3.4.1)\n",
            "Collecting pybind11<2.6.2 (from nmslib>=1.7.3.6->scispacy)\n",
            "  Using cached pybind11-2.6.1-py2.py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from nmslib>=1.7.3.6->scispacy) (5.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->scispacy) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->scispacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->scispacy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->scispacy) (2024.8.30)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.3->scispacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.5.0,>=3.4.0->scispacy) (1.2.0)\n",
            "Collecting pathlib-abc==0.1.1 (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->scispacy)\n",
            "  Downloading pathlib_abc-0.1.1-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->scispacy) (4.12.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->scispacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->scispacy) (0.1.5)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->scispacy) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->scispacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.5.0,>=3.4.0->scispacy) (1.2.1)\n",
            "Downloading scispacy-0.5.2-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading spacy-3.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading conllu-6.0.0-py3-none-any.whl (16 kB)\n",
            "Downloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pathy-0.11.0-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pathlib_abc-0.1.1-py3-none-any.whl (23 kB)\n",
            "Using cached pybind11-2.6.1-py2.py3-none-any.whl (188 kB)\n",
            "Downloading pydantic-1.10.19-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smart_open-6.4.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading thinc-8.1.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (919 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m919.6/919.6 kB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typer-0.7.0-py3-none-any.whl (38 kB)\n",
            "Downloading wasabi-0.10.1-py3-none-any.whl (26 kB)\n",
            "Building wheels for collected packages: en_ner_bionlp13cg_md, nmslib\n",
            "  Building wheel for en_ner_bionlp13cg_md (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en_ner_bionlp13cg_md: filename=en_ner_bionlp13cg_md-0.5.1-py3-none-any.whl size=120241137 sha256=6b99ffdf37348c65bc706cd52e5505cbc48acb9449216be4ea4dcf513182eae5\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/43/3c/7410e066024fdc38ff45fa67094b95c1eb398644e1d6c8a5f3\n",
            "  Building wheel for nmslib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nmslib: filename=nmslib-2.1.1-cp310-cp310-linux_x86_64.whl size=13578641 sha256=d92d0361c1ddb9db5afb11ddc7802a89cc1fc0df18747877be879fa64f5eb3fe\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/1a/5d/4cc754a5b1a88405cad184b76f823897a63a8d19afcd4b9314\n",
            "Successfully built en_ner_bionlp13cg_md nmslib\n",
            "Installing collected packages: wasabi, typer, smart-open, pysbd, pydantic, pybind11, pathlib-abc, conllu, pathy, nmslib, thinc, spacy, scispacy, en_ner_bionlp13cg_md\n",
            "  Attempting uninstall: wasabi\n",
            "    Found existing installation: wasabi 1.1.3\n",
            "    Uninstalling wasabi-1.1.3:\n",
            "      Successfully uninstalled wasabi-1.1.3\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.12.5\n",
            "    Uninstalling typer-0.12.5:\n",
            "      Successfully uninstalled typer-0.12.5\n",
            "  Attempting uninstall: smart-open\n",
            "    Found existing installation: smart-open 7.0.5\n",
            "    Uninstalling smart-open-7.0.5:\n",
            "      Successfully uninstalled smart-open-7.0.5\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.9.2\n",
            "    Uninstalling pydantic-2.9.2:\n",
            "      Successfully uninstalled pydantic-2.9.2\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 8.2.5\n",
            "    Uninstalling thinc-8.2.5:\n",
            "      Successfully uninstalled thinc-8.2.5\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.7.5\n",
            "    Uninstalling spacy-3.7.5:\n",
            "      Successfully uninstalled spacy-3.7.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 1.4.20 requires pydantic>=2.7.0, but you have pydantic 1.10.19 which is incompatible.\n",
            "en-core-web-sm 3.7.1 requires spacy<3.8.0,>=3.7.2, but you have spacy 3.4.4 which is incompatible.\n",
            "langchain 0.3.4 requires pydantic<3.0.0,>=2.7.4, but you have pydantic 1.10.19 which is incompatible.\n",
            "langchain-core 0.3.13 requires pydantic<3.0.0,>=2.5.2; python_full_version < \"3.12.4\", but you have pydantic 1.10.19 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed conllu-6.0.0 en_ner_bionlp13cg_md-0.5.1 nmslib-2.1.1 pathlib-abc-0.1.1 pathy-0.11.0 pybind11-2.6.1 pydantic-1.10.19 pysbd-0.3.4 scispacy-0.5.2 smart-open-6.4.0 spacy-3.4.4 thinc-8.1.12 typer-0.7.0 wasabi-0.10.1\n"
          ]
        }
      ],
      "source": [
        "!pip install scispacy https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_ner_bionlp13cg_md-0.5.1.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lA8-F2gtWA19",
        "outputId": "271b5015-9096-47f9-8727-3a2741b78496"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting reportlab\n",
            "  Downloading reportlab-4.2.5-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from reportlab) (10.4.0)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from reportlab) (5.2.0)\n",
            "Downloading reportlab-4.2.5-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: reportlab\n",
            "Successfully installed reportlab-4.2.5\n"
          ]
        }
      ],
      "source": [
        "!pip install reportlab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbXjM0i1ZKA3",
        "outputId": "1932ed91-bb43-4f67-bd60-ae4e5412ad7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyMuPDF\n",
            "  Downloading PyMuPDF-1.24.13-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading PyMuPDF-1.24.13-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (19.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDF\n",
            "Successfully installed PyMuPDF-1.24.13\n"
          ]
        }
      ],
      "source": [
        "!pip install PyMuPDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rj5GEgFlbPnh",
        "outputId": "31268cfc-b3a8-497b-d37f-a7921d28ef12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting groq\n",
            "  Downloading groq-0.11.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (5.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.12.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq) (0.27.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq) (1.10.19)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groq-0.11.0-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.5/106.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-docx, groq\n",
            "Successfully installed groq-0.11.0 python-docx-1.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install python-docx groq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iw9SnplmwpFS",
        "outputId": "ba009750-4a2c-4ac8-ccc1-c247d07ac903"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m153.6/232.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECqb1eSvMKI9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "import spacy\n",
        "from io import BytesIO\n",
        "from reportlab.lib.pagesizes import letter\n",
        "from reportlab.pdfgen import canvas\n",
        "from reportlab.lib import pagesizes, colors\n",
        "import fitz\n",
        "from groq import Groq\n",
        "from docx import Document\n",
        "import PyPDF2\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uaJyh4dqMSkJ"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load(\"en_ner_bionlp13cg_md\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddbU859VdoQx"
      },
      "outputs": [],
      "source": [
        "os.environ[\"GROQ_API_KEY\"] = \"\"\n",
        "api_key = os.getenv(\"GROQ_API_KEY\")\n",
        "client = Groq(api_key=api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "I5RtsshoUNB3"
      },
      "outputs": [],
      "source": [
        "def get_gene_info_ensembl(gene_name):\n",
        "    \"\"\"\n",
        "    Fetches gene information from the Ensembl REST API.\n",
        "    \"\"\"\n",
        "    url = f\"https://rest.ensembl.org/lookup/symbol/homo_sapiens/{gene_name}?content-type=application/json\"\n",
        "\n",
        "    response = requests.get(url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        gene_data = response.json()\n",
        "\n",
        "        gene_info = {\n",
        "            \"Gene Name\": gene_data.get(\"display_name\", \"N/A\"),\n",
        "            \"Gene Symbol\": gene_data.get(\"display_name\", \"N/A\"),\n",
        "            \"Gene ID\": gene_data.get(\"id\", \"N/A\"),\n",
        "            \"Chromosome\": gene_data.get(\"seq_region_name\", \"N/A\"),\n",
        "            \"Start\": gene_data.get(\"start\", \"N/A\"),\n",
        "            \"End\": gene_data.get(\"end\", \"N/A\")\n",
        "        }\n",
        "        return gene_info\n",
        "    else:\n",
        "        print(f\"Error fetching data from Ensembl for gene: {gene_name}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "q-Rw8Sf0UPNN"
      },
      "outputs": [],
      "source": [
        "def get_gene_function(gene_name):\n",
        "    \"\"\"\n",
        "    Fetches the gene function from mygene.info API.\n",
        "    \"\"\"\n",
        "    url = f\"https://mygene.info/v3/query?q={gene_name}&fields=symbol,name,summary\"\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        if 'hits' in data and len(data['hits']) > 0:\n",
        "            gene_info = data['hits'][0]\n",
        "            return {\n",
        "                \"symbol\": gene_info.get(\"symbol\", \"N/A\"),\n",
        "                \"name\": gene_info.get(\"name\", \"N/A\"),\n",
        "                \"summary\": gene_info.get(\"summary\", \"No function available\")\n",
        "            }\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "CMBvWiY8h7kJ"
      },
      "outputs": [],
      "source": [
        "def get_filtered_mutation_data_ensembl(gene_name, mutation_limit=5, mutation_type_filters=[\"stop_gained\"]):\n",
        "    \"\"\"\n",
        "    Fetches mutation data for a gene from Ensembl and applies filters for each mutation type separately.\n",
        "    Each mutation type gets its own limit.\n",
        "    \"\"\"\n",
        "    gene_info = get_gene_info_ensembl(gene_name)\n",
        "\n",
        "    if gene_info:\n",
        "        gene_id = gene_info[\"Gene ID\"]\n",
        "        print(f\"Fetching mutations for Gene ID: {gene_id}\")\n",
        "\n",
        "        url = f\"https://rest.ensembl.org/overlap/id/{gene_id}?feature=variation;content-type=application/json\"\n",
        "\n",
        "        response = requests.get(url)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            mutation_data = response.json()\n",
        "            print(f\"Received {len(mutation_data)} mutations from Ensembl.\")\n",
        "\n",
        "            mutations = []\n",
        "            seen_variants = set()\n",
        "            count_per_mutation_type = {mt: 0 for mt in mutation_type_filters}\n",
        "\n",
        "            for mutation in mutation_data:\n",
        "                variation_id = mutation.get(\"id\", \"N/A\")\n",
        "                if variation_id in seen_variants:\n",
        "                    continue\n",
        "\n",
        "                consequence_type = mutation.get(\"consequence_type\", [])\n",
        "\n",
        "                if isinstance(consequence_type, str):\n",
        "                    consequence_type = [consequence_type]\n",
        "\n",
        "                for mt in mutation_type_filters:\n",
        "                    if any(mt.lower() in consequence.lower() for consequence in consequence_type):\n",
        "                        if count_per_mutation_type[mt] >= mutation_limit:\n",
        "                            continue\n",
        "\n",
        "                        seq_region_name = mutation.get(\"seq_region_name\", \"N/A\")\n",
        "                        allele_string = mutation.get(\"allele_string\", \"N/A\")\n",
        "\n",
        "                        if allele_string == \"N/A\":\n",
        "                            allele_string = mutation.get(\"alleles\", \"N/A\")\n",
        "\n",
        "                        if isinstance(allele_string, list):\n",
        "                            allele_string = ', '.join(allele_string)\n",
        "\n",
        "                        mutation_dict = {\n",
        "                            \"Variation\": variation_id,\n",
        "                            \"Location\": seq_region_name,\n",
        "                            \"Allele\": allele_string,\n",
        "                            \"Consequence\": '/'.join(consequence_type),\n",
        "                        }\n",
        "                        mutations.append(mutation_dict)\n",
        "\n",
        "                        seen_variants.add(variation_id)\n",
        "\n",
        "                        count_per_mutation_type[mt] += 1\n",
        "\n",
        "                if all(count >= mutation_limit for count in count_per_mutation_type.values()):\n",
        "                    break\n",
        "\n",
        "            for mt in mutation_type_filters:\n",
        "                print(f\"Found {count_per_mutation_type[mt]} mutations for {mt}.\")\n",
        "\n",
        "            print(f\"Total filtered mutations: {len(mutations)}\")\n",
        "\n",
        "            return mutations if mutations else \"No mutations found that match the criteria.\"\n",
        "        else:\n",
        "            print(f\"Error fetching mutation data from Ensembl for gene ID: {gene_id}, status code: {response.status_code}\")\n",
        "            return \"Error fetching mutation data from Ensembl.\"\n",
        "    else:\n",
        "        print(f\"Gene information not found for {gene_name}\")\n",
        "        return \"Gene information not found.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "HNyETIoVUlmt"
      },
      "outputs": [],
      "source": [
        "def extract_text_from_pdf(pdf_content):\n",
        "    doc = fitz.open(stream=pdf_content, filetype=\"pdf\")\n",
        "    text = \"\"\n",
        "    for page in doc:\n",
        "        text += page.get_text()\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "FEGdfIeFUn1v"
      },
      "outputs": [],
      "source": [
        "def extract_entities(text):\n",
        "    doc = nlp(text)\n",
        "    entities = {\n",
        "        \"genes\": [],\n",
        "    }\n",
        "\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ == \"GENE_OR_GENE_PRODUCT\":\n",
        "            entities[\"genes\"].append(ent.text)\n",
        "\n",
        "    return entities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "Xufy16RAUq6G"
      },
      "outputs": [],
      "source": [
        "def chatbot_with_groq(question, context):\n",
        "    chat_completion = client.chat.completions.create(\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful genetic counseling assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": question},\n",
        "            {\"role\": \"system\", \"content\": f\"Context: {context}\"}\n",
        "        ],\n",
        "        model=\"llama3-8b-8192\",\n",
        "    )\n",
        "    return chat_completion.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_genes_from_txt(file_path):\n",
        "    \"\"\"\n",
        "    Extract genes from a plain text (.txt) file.\n",
        "    \"\"\"\n",
        "    with open(file_path, \"r\") as file:\n",
        "        text = file.read()\n",
        "    entities = extract_entities(text)\n",
        "    return entities[\"genes\"]"
      ],
      "metadata": {
        "id": "MgBsx6Bm09gf"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "IMFeRnPGrsHN"
      },
      "outputs": [],
      "source": [
        "def extract_genes_from_pdf(file_path):\n",
        "    with open(file_path, \"rb\") as f:\n",
        "        reader = PyPDF2.PdfReader(f)\n",
        "        text = \"\"\n",
        "        for page in reader.pages:\n",
        "            text += page.extract_text()\n",
        "        entities = extract_entities(text)\n",
        "        return entities[\"genes\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "EMLWYApyrsoN"
      },
      "outputs": [],
      "source": [
        "def extract_genes_from_docx(file_path):\n",
        "    doc = Document(file_path)\n",
        "    text = \"\"\n",
        "    for para in doc.paragraphs:\n",
        "        text += para.text\n",
        "    entities = extract_entities(text)\n",
        "    return entities[\"genes\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "Vicmc30RriqL"
      },
      "outputs": [],
      "source": [
        "def extract_genes_from_document(file_path):\n",
        "    \"\"\"\n",
        "    Extract genes from a document based on its file extension.\n",
        "    Supports PDF, DOCX, and TXT files.\n",
        "    \"\"\"\n",
        "    if file_path.endswith(\".pdf\"):\n",
        "        return extract_genes_from_pdf(file_path)\n",
        "    elif file_path.endswith(\".docx\"):\n",
        "        return extract_genes_from_docx(file_path)\n",
        "    elif file_path.endswith(\".txt\"):\n",
        "        return extract_genes_from_txt(file_path)\n",
        "    else:\n",
        "        print(\"Unsupported file type. Please upload a PDF, DOCX, or TXT file.\")\n",
        "        return []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "tsU2Xirmycxd"
      },
      "outputs": [],
      "source": [
        "def get_file_path_colab():\n",
        "    uploaded = files.upload()\n",
        "    file_path = list(uploaded.keys())[0]\n",
        "    return file_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "s0eHyrrp1VES"
      },
      "outputs": [],
      "source": [
        "def wrap_text(text, width, font_size, font_name=\"Helvetica\", x_offset=100):\n",
        "    \"\"\"\n",
        "    Wrap the text to fit within the given width and adjust for right padding.\n",
        "    \"\"\"\n",
        "    c = canvas.Canvas(BytesIO(), pagesize=letter)\n",
        "    c.setFont(font_name, font_size)\n",
        "    words = text.split(\" \")\n",
        "    lines = []\n",
        "    current_line = \"\"\n",
        "\n",
        "    for word in words:\n",
        "        test_line = current_line + \" \" + word if current_line else word\n",
        "        text_width = c.stringWidth(test_line, font_name, font_size)\n",
        "        if text_width <= width - x_offset - 100:\n",
        "            current_line = test_line\n",
        "        else:\n",
        "            lines.append(current_line)\n",
        "            current_line = word\n",
        "\n",
        "    if current_line:\n",
        "        lines.append(current_line)\n",
        "\n",
        "    return lines\n",
        "\n",
        "def draw_underline(c, text, x_position, y_position, font_name=\"Helvetica-Bold\", font_size=12, x_offset=100, line_padding=0):\n",
        "    \"\"\"\n",
        "    Draw an underline beneath the text at the given position with more padding from the right.\n",
        "    \"\"\"\n",
        "    text_width = c.stringWidth(text, font_name, font_size)\n",
        "    c.drawString(x_position, y_position, text)\n",
        "    c.line(x_position, y_position - 2, x_position + text_width + line_padding, y_position - 2)\n",
        "\n",
        "def draw_full_line(c, y_position, width=500, x_offset=100, line_padding=0):\n",
        "    \"\"\"\n",
        "    Draw a full-width horizontal line to separate gene sections with more right padding.\n",
        "    \"\"\"\n",
        "    c.setStrokeColorRGB(0, 0, 0)\n",
        "    c.setLineWidth(1)\n",
        "    c.line(x_offset, y_position, x_offset + width + line_padding, y_position)\n",
        "\n",
        "def generate_report(genes_data):\n",
        "    \"\"\"\n",
        "    Generate a combined PDF report for multiple genes with improved formatting and page handling.\n",
        "    \"\"\"\n",
        "    buffer = BytesIO()\n",
        "    c = canvas.Canvas(buffer, pagesize=letter)\n",
        "    width, height = letter\n",
        "    c.setFont(\"Helvetica\", 14)\n",
        "\n",
        "    header_height = 50\n",
        "    footer_height = 40\n",
        "    content_top_margin = 80\n",
        "    content_bottom_margin = footer_height + 20\n",
        "    x_offset = 120\n",
        "\n",
        "    y_position = height - header_height - 20\n",
        "\n",
        "    c.setFillColorRGB(0.2, 0.4, 0.6)\n",
        "    c.drawString(x_offset, y_position, \"Genetic Counseling Report\")\n",
        "    y_position -= 30\n",
        "\n",
        "    def check_page_break(y_position):\n",
        "        \"\"\"Check if the current y_position is too low and a page break is needed\"\"\"\n",
        "        if y_position < content_bottom_margin:\n",
        "            c.showPage()\n",
        "            c.setFont(\"Helvetica\", 14)\n",
        "            c.setFillColorRGB(0.2, 0.4, 0.6)\n",
        "            y_position = height - header_height - 20\n",
        "            c.drawString(x_offset, y_position, \"Genetic Counseling Report\")\n",
        "            y_position -= 30\n",
        "\n",
        "            c.setFont(\"Helvetica\", 10)\n",
        "        return y_position\n",
        "\n",
        "    for gene_data in genes_data:\n",
        "        gene_info, gene_function, mutations = gene_data\n",
        "\n",
        "        c.setFont(\"Helvetica-Bold\", 12)\n",
        "        draw_underline(c, f\"Gene Information: {gene_info.get('Gene Symbol', 'N/A')}\", x_offset, y_position, x_offset=x_offset)\n",
        "        y_position -= 30\n",
        "\n",
        "        y_position = check_page_break(y_position)\n",
        "\n",
        "        c.setFont(\"Helvetica\", 10)\n",
        "        if gene_info:\n",
        "            for key, value in gene_info.items():\n",
        "                lines = wrap_text(f\"{key}: {value}\", width, 10, x_offset=x_offset)\n",
        "                for line in lines:\n",
        "                    y_position = check_page_break(y_position)\n",
        "                    c.drawString(x_offset, y_position, line)\n",
        "                    y_position -= 15\n",
        "        else:\n",
        "            c.drawString(x_offset, y_position, \"No gene information available.\")\n",
        "            y_position -= 20\n",
        "\n",
        "        y_position -= 20\n",
        "\n",
        "        c.setFont(\"Helvetica-Bold\", 12)\n",
        "        draw_underline(c, \"Gene Function:\", x_offset, y_position, x_offset=x_offset)\n",
        "        y_position -= 30\n",
        "        y_position = check_page_break(y_position)\n",
        "        c.setFont(\"Helvetica\", 10)\n",
        "\n",
        "        if gene_function:\n",
        "            lines = wrap_text(f\"Name: {gene_function['name']}\", width, 10, x_offset=x_offset)\n",
        "            for line in lines:\n",
        "                y_position = check_page_break(y_position)\n",
        "                c.drawString(x_offset, y_position, line)\n",
        "                y_position -= 15\n",
        "\n",
        "            lines = wrap_text(f\"Symbol: {gene_function['symbol']}\", width, 10, x_offset=x_offset)\n",
        "            for line in lines:\n",
        "                y_position = check_page_break(y_position)\n",
        "                c.drawString(x_offset, y_position, line)\n",
        "                y_position -= 15\n",
        "\n",
        "            lines = wrap_text(f\"Function Summary: {gene_function['summary']}\", width, 10, x_offset=x_offset)\n",
        "            for line in lines:\n",
        "                y_position = check_page_break(y_position)\n",
        "                c.drawString(x_offset, y_position, line)\n",
        "                y_position -= 15\n",
        "        else:\n",
        "            c.drawString(x_offset, y_position, \"No gene function information available.\")\n",
        "            y_position -= 20\n",
        "\n",
        "        y_position -= 40\n",
        "\n",
        "        c.setFont(\"Helvetica-Bold\", 12)\n",
        "        draw_underline(c, \"Mutation Interpretation:\", x_offset, y_position, x_offset=x_offset)\n",
        "        y_position -= 30\n",
        "        y_position = check_page_break(y_position)\n",
        "        c.setFont(\"Helvetica\", 10)\n",
        "\n",
        "        if mutations:\n",
        "            for mutation in mutations:\n",
        "                lines = wrap_text(f\"Variation: {mutation['Variation']}\", width, 10, x_offset=x_offset)\n",
        "                for line in lines:\n",
        "                    y_position = check_page_break(y_position)\n",
        "                    c.drawString(x_offset, y_position, line)\n",
        "                    y_position -= 15\n",
        "\n",
        "                lines = wrap_text(f\"Location: {mutation['Location']}\", width, 10, x_offset=x_offset)\n",
        "                for line in lines:\n",
        "                    y_position = check_page_break(y_position)\n",
        "                    c.drawString(x_offset, y_position, line)\n",
        "                    y_position -= 15\n",
        "\n",
        "                lines = wrap_text(f\"Consequence: {mutation['Consequence']}\", width, 10, x_offset=x_offset)\n",
        "                for line in lines:\n",
        "                    y_position = check_page_break(y_position)\n",
        "                    c.drawString(x_offset, y_position, line)\n",
        "                    y_position -= 15\n",
        "\n",
        "                lines = wrap_text(f\"Alleles: {mutation['Allele']}\", width, 10, x_offset=x_offset)\n",
        "                for line in lines:\n",
        "                    y_position = check_page_break(y_position)\n",
        "                    c.drawString(x_offset, y_position, line)\n",
        "                    y_position -= 15\n",
        "\n",
        "                y_position -= 20\n",
        "        else:\n",
        "            c.drawString(x_offset, y_position, \"No mutation information available.\")\n",
        "            y_position -= 20\n",
        "\n",
        "        y_position -= 40\n",
        "        draw_full_line(c, y_position, width=500, x_offset=x_offset, line_padding=20)\n",
        "        y_position -= 40\n",
        "\n",
        "    c.showPage()\n",
        "    c.save()\n",
        "    pdf_content = buffer.getvalue()\n",
        "    buffer.close()\n",
        "    return pdf_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "Jl3k9YfW1V_D"
      },
      "outputs": [],
      "source": [
        "def extract_valid_genes_from_document(file_path):\n",
        "    extracted_genes = extract_genes_from_document(file_path)\n",
        "    valid_genes = []\n",
        "\n",
        "    for gene in extracted_genes:\n",
        "        gene_info = get_gene_info_ensembl(gene)\n",
        "        if gene_info:\n",
        "            valid_genes.append(gene)\n",
        "\n",
        "    return valid_genes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_consequences_from_user():\n",
        "    so_terms = [\n",
        "        \"transcript_ablation\",\n",
        "        \"splice_acceptor_variant\",\n",
        "        \"splice_donor_variant\",\n",
        "        \"stop_gained\",\n",
        "        \"frameshift_variant\",\n",
        "        \"stop_lost\",\n",
        "        \"start_lost\",\n",
        "        \"transcript_amplification\",\n",
        "        \"feature_elongation\",\n",
        "        \"feature_truncation\",\n",
        "        \"inframe_insertion\",\n",
        "        \"inframe_deletion\",\n",
        "        \"missense_variant\",\n",
        "        \"protein_altering_variant\",\n",
        "        \"splice_donor_5th_base_variant\",\n",
        "        \"splice_region_variant\",\n",
        "        \"splice_donor_region_variant\",\n",
        "        \"splice_polypyrimidine_tract_variant\",\n",
        "        \"incomplete_terminal_codon_variant\",\n",
        "        \"start_retained_variant\",\n",
        "        \"stop_retained_variant\",\n",
        "        \"synonymous_variant\",\n",
        "        \"coding_sequence_variant\",\n",
        "        \"mature_miRNA_variant\",\n",
        "        \"5_prime_UTR_variant\",\n",
        "        \"3_prime_UTR_variant\",\n",
        "        \"non_coding_transcript_exon_variant\",\n",
        "        \"intron_variant\",\n",
        "        \"NMD_transcript_variant\",\n",
        "        \"non_coding_transcript_variant\",\n",
        "        \"coding_transcript_variant\",\n",
        "        \"upstream_gene_variant\",\n",
        "        \"downstream_gene_variant\",\n",
        "        \"TFBS_ablation\",\n",
        "        \"TFBS_amplification\",\n",
        "        \"TF_binding_site_variant\",\n",
        "        \"regulatory_region_ablation\",\n",
        "        \"regulatory_region_amplification\",\n",
        "        \"regulatory_region_variant\",\n",
        "        \"intergenic_variant\"\n",
        "    ]\n",
        "\n",
        "    print(\"\\nValid Mutation Consequences:\")\n",
        "    for term in so_terms:\n",
        "        print(f\"- {term}\")\n",
        "\n",
        "    while True:\n",
        "        consequences_input = input(\"Enter the mutation consequences you are interested in (comma-separated): \").split(',')\n",
        "\n",
        "        consequences_input = [term.strip() for term in consequences_input]\n",
        "\n",
        "        if all(consequence in so_terms for consequence in consequences_input):\n",
        "            return consequences_input\n",
        "        else:\n",
        "            print(\"Invalid input. Please enter only the valid consequences from the list above.\")"
      ],
      "metadata": {
        "id": "Vc71kjvy7LIj"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "HJedv0ut1ZD_"
      },
      "outputs": [],
      "source": [
        "def genetic_counseling_assistant():\n",
        "    while True:\n",
        "        choice = input(\"Do you want to upload a file with gene names? (y/n): \").lower()\n",
        "\n",
        "        while choice not in [\"y\", \"n\"]:\n",
        "            print(\"Invalid choice. Please enter 'y' for yes or 'n' for no.\")\n",
        "            choice = input(\"Do you want to upload a file with gene names? (y/n): \").lower()\n",
        "\n",
        "        if choice == \"y\":\n",
        "            while True:\n",
        "                file_path = get_file_path_colab()\n",
        "                if file_path.endswith(('.pdf', '.docx', '.txt')):\n",
        "                    genes = extract_valid_genes_from_document(file_path)\n",
        "                    break\n",
        "                else:\n",
        "                    print(\"Unsupported file type. Please upload a PDF, DOCX, or TXT file.\")\n",
        "\n",
        "        elif choice == \"n\":\n",
        "            gene_name = input(\"Enter a gene name: \")\n",
        "            genes = [gene_name]\n",
        "\n",
        "        genes = list(set(genes))\n",
        "\n",
        "        while True:\n",
        "            try:\n",
        "                mutation_limit = int(input(\"Enter the number of mutations to retrieve (default 5): \") or 5)\n",
        "                break\n",
        "            except ValueError:\n",
        "                print(\"Invalid input. Please enter a valid number.\")\n",
        "\n",
        "        consequences = get_consequences_from_user()\n",
        "\n",
        "        genes_data = []\n",
        "\n",
        "        for gene in genes:\n",
        "            gene_info = get_gene_info_ensembl(gene)\n",
        "            gene_function = get_gene_function(gene)\n",
        "            mutations = get_filtered_mutation_data_ensembl(gene, mutation_limit, consequences)\n",
        "\n",
        "            genes_data.append((gene_info, gene_function, mutations))\n",
        "\n",
        "        if genes_data:\n",
        "            report_content = generate_report(genes_data)\n",
        "            with open(\"genetic_counseling_report.pdf\", \"wb\") as f:\n",
        "                f.write(report_content)\n",
        "            print(\"Genetic Counseling Report has been generated and saved as 'genetic_counseling_report.pdf'\")\n",
        "\n",
        "        complete_context = \"\"\n",
        "        for gene_data in genes_data:\n",
        "            gene_info, gene_function, mutations = gene_data\n",
        "            complete_context += f\"Gene Information: {gene_info if gene_info else 'None'}\\n\"\n",
        "            complete_context += f\"Gene Function: {gene_function if gene_function else 'None'}\\n\"\n",
        "            complete_context += f\"Mutation Data: {mutations if mutations else 'None'}\\n\\n\"\n",
        "\n",
        "        while True:\n",
        "            follow_up_question = input(\"Do you have any follow-up questions related to genetic counseling? (yes/no): \").lower()\n",
        "\n",
        "            while follow_up_question not in ['yes', 'no']:\n",
        "                print(\"Invalid input. Please enter 'yes' or 'no'.\")\n",
        "                follow_up_question = input(\"Do you have any follow-up questions related to genetic counseling? (yes/no): \").lower()\n",
        "\n",
        "            if follow_up_question == \"yes\":\n",
        "                question = input(\"Please enter your follow-up question: \")\n",
        "\n",
        "                response = chatbot_with_groq(question, complete_context)\n",
        "                print(f\"Chatbot Response: {response}\")\n",
        "\n",
        "            elif follow_up_question == \"no\":\n",
        "                print(\"Thank you for using the Genetic Counseling Assistant! Have a great day!\")\n",
        "                break\n",
        "\n",
        "        continue_session = input(\"Would you like to process another set of gene data? (yes/no): \").lower()\n",
        "\n",
        "        while continue_session not in ['yes', 'no']:\n",
        "            print(\"Invalid input. Please enter 'yes' or 'no'.\")\n",
        "            continue_session = input(\"Would you like to process another set of gene data? (yes/no): \").lower()\n",
        "\n",
        "        if continue_session != \"yes\":\n",
        "            print(\"Goodbye!\")\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kX_4S7F91czN"
      },
      "outputs": [],
      "source": [
        "genetic_counseling_assistant()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}